{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step by step guide for converting tensorflow weight files to tflite model\n",
        "## Make sure to run on GPU\n",
        "## Make sure to uncomment and install all the dependencies"
      ],
      "metadata": {
        "id": "YRXJCvyXxVfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH = # /env/python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WoXw5hH95KF",
        "outputId": "be233d9f-8f1a-4d50-f330-a8d946fbcaf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=# /env/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkliIM3L-BBk",
        "outputId": "1063ffc1-9f0f-48de-f324-3c909767d96b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-04 04:35:51--  https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76120962 (73M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py38_4.12.0-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py38_4.1 100%[===================>]  72.59M   225MB/s    in 0.3s    \n",
            "\n",
            "2023-10-04 04:35:51 (225 MB/s) - ‘Miniconda3-py38_4.12.0-Linux-x86_64.sh’ saved [76120962/76120962]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x Miniconda3-py38_4.12.0-Linux-x86_64.sh"
      ],
      "metadata": {
        "id": "JUuGVcHl-ET4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./Miniconda3-py38_4.12.0-Linux-x86_64.sh -b -f -p /usr/local"
      ],
      "metadata": {
        "id": "KDpc2run-EXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda update conda"
      ],
      "metadata": {
        "id": "Psfrga6i-Ead"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.8/site-packages')"
      ],
      "metadata": {
        "id": "JT0M5xHx-Edk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n myenv python=3.6"
      ],
      "metadata": {
        "id": "WOi17ro_-rX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install tensorflow==1.15\n",
        "pip install Pillow"
      ],
      "metadata": {
        "id": "Z_8JjrKM-uu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "python3 /content/convert.py   # convert.py is in folder directory, This will generate the model.pb file from .weights file, change class names file accordingly, you can pass class.txt with all the class names\n",
        "\n"
      ],
      "metadata": {
        "id": "60laBrUV--rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w_HvuYluyG2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This part is for converting the model.pb file to tflite"
      ],
      "metadata": {
        "id": "76fkiHEw0i6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "gf = tf.GraphDef()\n",
        "m_file = open('/content/frozen_darknet_yolov3_model.pb','rb')\n",
        "gf.ParseFromString(m_file.read())\n",
        "\n",
        "with open('somefile.txt', 'a') as the_file:\n",
        "     for n in gf.node:\n",
        "         the_file.write(n.name+'\\n')\n",
        "\n",
        "file = open('somefile.txt','r')\n",
        "data = file.readlines()\n",
        "output = data[len(data)-1]\n",
        "print(\"Output array = \", output)\n",
        "\n",
        "file.seek ( 0 )\n",
        "input=file.readline()\n",
        "print(\"Input array = \", input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WDM5zcwAhqZ",
        "outputId": "fffc5c00-5bd4-4214-b2b9-302433a59c40"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output array =  output_boxes\n",
            "\n",
            "Input array =  inputs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import os\n",
        "converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\n",
        "    graph_def_file='/content/frozen_darknet_yolov3_model.pb',\n",
        "    input_arrays = ['inputs'],   # Here, 'inputs' is the value of input array from Step 7b\n",
        "    output_arrays = ['output_boxes'], # Here, 'output_boxes' is the value of output array from Step 7b\n",
        "    input_shapes={'inputs': [1, 416, 416, 3]} # Here, 'inputs' is the value of input array from Step 7b\n",
        ")\n",
        "\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Convert to TFLite Model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# _, dynamic_tflite_path = tempfile.mkstemp('.tflite')\n",
        "tflite_path='/content/model.tflite'\n",
        "tflite_model_size = open(tflite_path, 'wb').write(tflite_model)\n",
        "tf_model_size = os.path.getsize('/content/frozen_darknet_yolov3_model.pb')\n",
        "print('TensorFlow Model is  {} bytes'.format(tf_model_size))\n",
        "print('TFLite Model is      {} bytes'.format(tflite_model_size))\n",
        "print('Post training dynamic range quantization saves {} bytes'.format(tf_model_size-tflite_model_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNiitj7JA1y-",
        "outputId": "e749bd0d-696a-4082-ee40-72a6b77e85ed"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Model is  246517284 bytes\n",
            "TFLite Model is      62138672 bytes\n",
            "Post training dynamic range quantization saves 184378612 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh {dynamic_tflite_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXbtakuFBP6a",
        "outputId": "6af82f3b-e873-40dc-e50f-b8e9cfe3bbe9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 60M Oct  4 09:45 /tmp/tmp8q6nqofj.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "tflite_file = ''\n",
        "tflite_file = tflite_file.join(glob.glob(\"/tmp/*.tflite\")) # Find the temp file of type .tflite\n",
        "tflite_file = tflite_file[5:len(tflite_file)]  # Extract .tflite file name.\n",
        "\n",
        "%cd ..\n",
        "%cd ../tmp\n",
        "!ls\n",
        "# # os.rename(tflite_file, 'detect.tflite') #Rename the temp .tflite to detect.tflite\n",
        "# %mv tmpry_03hf4.tflite ../content/gdrive/MyDrive/YOLOv3_TFLite/  # Move detect.tflite to Goolge Drive"
      ],
      "metadata": {
        "id": "rnylwL9yCjWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install opencv-python\n",
        "# !pip install tensorflow\n",
        "!pip install Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgd9ebPvGRbB",
        "outputId": "aa16513e-370b-4d7b-fea9-ac1401d5bf6a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow\n",
            "  Obtaining dependency information for Pillow from https://files.pythonhosted.org/packages/cd/6d/07566c00ddb116a0eca1a623abda12da81099a6ff3200e5e6b7e2d3c8c2b/Pillow-10.0.1-cp38-cp38-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading Pillow-10.0.1-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Downloading Pillow-10.0.1-cp38-cp38-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "Successfully installed Pillow-10.0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /test_tflite.py  # this is for inferencing with generated tflite file\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw1qFnmwC3wp",
        "outputId": "43b6ff03-c494-4183-d696-6c969e98e5f0"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-04 10:18:43.021946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "[{'name': 'output_boxes', 'index': 407, 'shape': array([    1, 10647,     8], dtype=int32), 'shape_signature': array([    1, 10647,     8], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "\n",
            "Predicted image saved as output.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tool\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKyvqx8cDKO1",
        "outputId": "745a8142-aa1a-4a95-dcd4-46bd1b24d455"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tool\n",
            "  Downloading tool-0.8.0.tar.gz (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.6/51.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting argh>=0.2.0 (from tool)\n",
            "  Downloading argh-0.29.4-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydispatcher>=2.0.1 (from tool)\n",
            "  Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pyyaml>=3.08 in /usr/local/lib/python3.10/dist-packages (from tool) (6.0.1)\n",
            "Building wheels for collected packages: tool\n",
            "  Building wheel for tool (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tool: filename=tool-0.8.0-py3-none-any.whl size=70547 sha256=fe14d77a3ccf2fb592cd5c852b339aefd80baaf974e4467f6d7159db9f812dd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/e3/85/55d80f5c19223845ba8c7e581b152b047394e9487416ba853b\n",
            "Successfully built tool\n",
            "Installing collected packages: pydispatcher, argh, tool\n",
            "Successfully installed argh-0.29.4 pydispatcher-2.0.7 tool-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/linghu8812/tensorrt_inference.git # this repo is for converting the model to onnx format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrvl6Vz0H1rL",
        "outputId": "46eb8070-4f3d-49db-893a-ae466d34326f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tensorrt_inference'...\n",
            "remote: Enumerating objects: 1443, done.\u001b[K\n",
            "remote: Counting objects: 100% (1439/1439), done.\u001b[K\n",
            "remote: Compressing objects: 100% (694/694), done.\u001b[K\n",
            "remote: Total 1443 (delta 783), reused 1318 (delta 685), pack-reused 4\u001b[K\n",
            "Receiving objects: 100% (1443/1443), 12.01 MiB | 15.31 MiB/s, done.\n",
            "Resolving deltas: 100% (783/783), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPb51zWrkGMg",
        "outputId": "ce739208-b505-4bf3-d4b8-ad2c0d32d487"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.5.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python3 export_onnx.py --cfg_file /content/gesture.cfg --weights_file /content/drive/MyDrive/yc_gesture_final.weights --output_file yolov3.onnx --strides 32 16 8 --neck FPN\n",
        "# The above line converts the weights and cfg from trained tensorflow model to onnx format"
      ],
      "metadata": {
        "id": "ggfozVNeiv4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/linghu8812/YOLOv3-TensorRT.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTg0gBmlk7Vb",
        "outputId": "968ca91b-4a62-4fe3-e175-8cc0e1c2fcb4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOv3-TensorRT'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 55 (delta 0), reused 0 (delta 0), pack-reused 52\u001b[K\n",
            "Receiving objects: 100% (55/55), 1.49 MiB | 2.06 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROAlNhNylDZ8",
        "outputId": "5bc2cdc7-0761-4453-e5fe-4d9282f970ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m786.0 kB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2023.1.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp310-cp310-linux_x86_64.whl size=661265 sha256=615df6d840167ec7981366f48568d9a161f3684d74b221a05f36c46f11596652\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/7b/06/82a395a243fce00035dea9914d92bbef0013401497d849f8bc\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.4 pycuda-2022.2.2 pytools-2023.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvidia-tensorrt==7.2.* --index-url https://pypi.ngc.nvidia.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0od9B4RmJ0Q",
        "outputId": "6336d550-4aaf-4151-950e-34b0c7bf4267"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.ngc.nvidia.com\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement nvidia-tensorrt==7.2.* (from versions: 8.4.0.6, 8.4.1.5, 8.4.2.4, 8.4.3.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for nvidia-tensorrt==7.2.*\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !python3 /content/YOLOv3-TensorRT/onnx_to_tensorrt.py --onnx_file /content/yolov3.onnx --engine_file yolov3.trt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V14N_GhtlT68",
        "outputId": "30cc46de-d689-4699-e1c6-70fb9f7142d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(width=608, height=608, batch_size=1, dataset='coco_labels.txt', int8=False, calib_file='yolo_calibration.cache', onnx_file='/content/yolov3.onnx', engine_file='yolov3.trt', image_file='/content/try.png', result_file='gesture_bboxes.png')\n",
            "[10/05/2023-07:26:51] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n",
            "[10/05/2023-07:26:51] [TRT] [W] The implicit batch dimension mode has been deprecated. Please create the network with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag whenever possible.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/YOLOv3-TensorRT/onnx_to_tensorrt.py\", line 179, in <module>\n",
            "    main(args.width, args.height, args.batch_size, args.dataset, args.int8, args.calib_file, args.onnx_file, args.engine_file,\n",
            "  File \"/content/YOLOv3-TensorRT/onnx_to_tensorrt.py\", line 130, in main\n",
            "    with get_engine(onnx_file_path, width, height, batch_size, engine_file_path, int8mode, calib_file) as engine, \\\n",
            "  File \"/content/YOLOv3-TensorRT/onnx_to_tensorrt.py\", line 98, in get_engine\n",
            "    return build_engine()\n",
            "  File \"/content/YOLOv3-TensorRT/onnx_to_tensorrt.py\", line 64, in build_engine\n",
            "    builder.max_workspace_size = 1 << 30  # 256MiB\n",
            "AttributeError: 'tensorrt_bindings.tensorrt.Builder' object has no attribute 'max_workspace_size'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Qj8N8pZtTiV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}